\documentclass{article}

\usepackage{algorithm}
\usepackage{algpseudocodex}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{natbib}
\usepackage{parskip}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{tikz}

\usetikzlibrary{positioning}

\title{Replicating `Deep Learning and the Game of Checkers'}

\author{Daniel David N. Bador \and Brymer Bernard R. Meneses}

\date{\today}

\doublespacing
\begin{document}

\maketitle

The paper by \cite{Popic_Boskovic_Brest_2021} managed to demonstrate the ability of an AlphaZero-based approach to learning the game of Checkers when given only the game rules. The approach is only given a set of game rules. The data needed to train newer models of neural networks are generated by self-play. Nine different versions of the neural network were obtained after two weeks of runtime, each better than the previous one.

\cite{Popic_Boskovic_Brest_2021} ran fifty games between an agent using the ninth version of the neural network model marked as the best and agents using every other versions of the neural network. Every game was scored according to the chess scoring. Number of wins (W), draws (D), and losses(L) of the ninth version of the neural network versus other versions as well as the final score (S) can be seen in Table \ref{tab:v9_summary}.

\begin{table}[htb]
    \centering
    \begin{tabular}{c|cccccccccc}
        & v0 & v1 & v2 & v3 & v4 & v5 & v6 & v7 & v8 & v9 \\ \hline
        W & 32 & 27 & 26 & 33 & 29 & 26 & 18 & 11 & 14 & 17 \\
        D & 13 & 18 & 19 & 10 & 17 & 13 & 16 & 20 & 14 & 16 \\
        L & 5 & 5 & 5 & 7 & 4 & 11 & 16 & 19 & 22 & 17 \\ \hline
        S & 109 & 99 & 97 & 109 & 104 & 91 & 70 & 53 & 56 & 67
    \end{tabular}
    \caption{Games of the Agent using the Ninth Version of the Neural Network Against All Other Versions of the Neural Network in \cite{Popic_Boskovic_Brest_2021}}
    \label{tab:v9_summary}
\end{table}

The final scores against lower and worse versions of the neural network are generally higher than those against higher and better versions. The number of wins generally decreases and the number of losses generally increases. The ninth version of the neural network obtained the same number of wins and losses when playing against itself, as shown in the ninth column of Table \ref{tab:v9_summary}, which is on par with the idea that two equivalent players will have the same chances of winning and losing.

\begin{table}[htb]
    \centering
    \begin{tabular}{c|cccccc}
        & v0 & v1 & v2 & v3 & v4 & v5 \\ \hline
        W & 32 & 28 & 26 & 26 & 18 & 17 \\
        D & 15 & 18 & 19 & 13 & 16 & 16 \\
        L & 3 & 4 & 5 & 11 & 16 & 17 \\ \hline
        S & 111 & 102 & 97 & 91 & 70 & 67
    \end{tabular}
    \caption{Games of the Agent using the Fifth Version of the Neural Network Against All Other Versions of the Neural Network by Replicating \cite{Popic_Boskovic_Brest_2021}}
    \label{tab:replication-results}
\end{table}

We were able to get the results shown in Table \ref{tab:replication-results} after running the algorithm on an Amazon Web Service Elastic Cloud Compute t2.micro instance having a single virtual central processing unit of Intel Xeon scalable processor running up to 3.3 gigahertz of clock speed and a gibibyte of memory. We were able to get 5 different versions of the model with each newer model being better than the previous model after a week. Similar trends are seen in the results of the replication compared to the results of the original paper.

The replication of \cite{Popic_Boskovic_Brest_2021} managed to demonstrate the ability of an AlphaZero-based approach to learning the game of Checkers when given only the game rules. The data needed to train newer models of neural network are generated by self-play. Five different versions of the neural network were obtained after a week of runtime, each better than the previous one. Similar results of the replication compared to the results of the original paper suggests that the algorithm works and is feasible to run given an ample amount of time.

\bibliographystyle{apalike}
\bibliography{references}

\end{document}